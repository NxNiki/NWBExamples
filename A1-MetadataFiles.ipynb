{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "historical-friend",
   "metadata": {},
   "source": [
    "# A1: Meta Data Files\n",
    "\n",
    "For organizing data into NWB files, there is a lot of 'metadata' that needs to be organized and accessed. \n",
    "\n",
    "There are different types of metadata relating to, for example, the study, task, participant, equipment, etc. This information is a mix of general information (the same across all participants) and custom information (for a given subject), and includes elements that can be automatically parsed and added, and information that may require some manual setting. \n",
    "\n",
    "A potential option for managing this information is to adopt a readable file format, most likely borrowing from a common config file. Then, converting data for a new session can load a set of metadata files that are reflect information for different elements of session (for example: the study file, the task file, the site file, etc).\n",
    "\n",
    "The desired file type is therefore something:\n",
    "- machine readable (to be automatically loaded and applied during file conversion)\n",
    "- human read and write-able, so that people organizing the data can edit as needed\n",
    "    - if they are easy to interact with for manual elements, this hopefully minimizes errors\n",
    "\n",
    "Potential 'config' file types:\n",
    "- txt\n",
    "    - Pro: simple, universal; CON: no particular structure, so parsing is annoying\n",
    "- ini / cfg\n",
    "    - Pro: simple, natively supported in Python, CON: I don't think it supports longer strings well\n",
    "- json\n",
    "    - Pro: simple, natively supported in Python; CON: a little more annoying to read / write (I think), no comments\n",
    "- yaml\n",
    "    - Pro: well supported, clean to write & supports longer strings, has comments; CON: not native in Python, more complex\n",
    "    \n",
    "The most relevant files for our purposes are probably YAML & JSON. YAML is potentially a bit better for 'human maintained' files, which might make it slightly preferred. Note that some information that needs to be listed may be relatively lengthy strings and/or lists of elements (somewhat stretching the notion of a \"config\" file). \n",
    "\n",
    "Metadata files for a particular experiment / task  will have to be initially written out, defining metadata fields and descriptions of interest. Once these files are set up, converting a new session of data should be largely automated, requiring minimal manual intervention to set custom metadata values. We do want to be flexible to metadata that may be collected / transmitted in variable ways, requiring some manual organization. This setup should allow for someone responsible for receiving & organizing data to do manual curation, as needed, and to make this easy to integrate into the pipeline. \n",
    "\n",
    "A possible alternative is to write in the metadata into the Python code and scripts that do the file conversion. This is what is done in the Rutishauser dataset (see [this file](https://github.com/rutishauserlab/recogmem-release-NWB/blob/master/RutishauserLabtoNWB/events/newolddelay/python/export/no2nwb.py) for example). This approach has limitations of mixing code & data in ways that are not very modular, and may make it more difficult to manually interact with metadata and customize things as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rough-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "convinced-isolation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as pjoin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-promotion",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "veterinary-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define director where metadata files are located\n",
    "metadata_folder = 'metadata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stupid-township",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_config.json', 'test_config.yaml', 'subject_info.yaml', 'test_config.cfg', 'test_ini.ini', '.ipynb_checkpoints', 'site_info.yaml', 'task_info.yaml']\n"
     ]
    }
   ],
   "source": [
    "# Define \n",
    "metadata_files = os.listdir(metadata_folder)\n",
    "print(metadata_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "applicable-barrel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_filter(files, ext):\n",
    "    return [file for file in files if ext in file]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-diana",
   "metadata": {},
   "source": [
    "## Config Files (cfg / ini)\n",
    "\n",
    "Note that (I think) [INI files](https://en.wikipedia.org/wiki/INI_file) and what are sometimes called given the `.cfg` extension in Python are effectively the same thing. \n",
    "\n",
    "These files are supported by the `configparser` module. \n",
    "\n",
    "Relevant pages:\n",
    "- https://docs.python.org/3/library/configparser.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "skilled-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rocky-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "cparser = configparser.ConfigParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dependent-nation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_config.cfg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ini_files = file_filter(metadata_files, '.cfg')\n",
    "ini_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "rough-elevation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['metadata/test_config.cfg']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cparser.read(pjoin(metadata_folder, ini_files[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "substantial-april",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Recording', 'Device', 'Task']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cparser.sections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "innocent-february",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location\n",
      "value\n"
     ]
    }
   ],
   "source": [
    "for key in cparser['Recording']:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "integral-bangkok",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Baylor Hospital'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cparser['Recording']['location']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-difficulty",
   "metadata": {},
   "source": [
    "## YAML\n",
    "\n",
    "Relevant pages:\n",
    "- https://www.cloudbees.com/blog/yaml-tutorial-everything-you-need-get-started/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "suitable-provision",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "centered-string",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_config.yaml', 'subject_info.yaml', 'site_info.yaml', 'task_info.yaml']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yaml_files = file_filter(metadata_files, '.yaml')\n",
    "yaml_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sufficient-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pjoin(metadata_folder,  yaml_files[0]), 'r') as stream:\n",
    "    data = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "departmental-synthetic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "radio-springfield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'xx',\n",
       " 'description': 'This is a description of a thing that uses a whole bunch of words.',\n",
       " 'keywords': ['neurosurgery', 'single-units']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-glucose",
   "metadata": {},
   "source": [
    "## JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "activated-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "improved-jonathan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_config.json']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_files = file_filter(metadata_files, '.json')\n",
    "json_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "incoming-alexandria",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pjoin(metadata_folder,  json_files[0]), 'r') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "liked-faith",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1111,\n",
       " 'name': 'xx',\n",
       " 'description': 'This is a description of a thing that uses a whole bunch of words.',\n",
       " 'keywords': ['neurosurgery', 'single-units']}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
